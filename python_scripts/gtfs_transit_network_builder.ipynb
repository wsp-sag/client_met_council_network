{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import partridge as ptg\n",
    "import peartree as pt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import networkx as nx\n",
    "from shapely import wkt\n",
    "from scipy.spatial import cKDTree\n",
    "import osmnx as ox\n",
    "from dbfread import DBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = \"C:/Users/wangs1/Documents/Met_Council/gtfs_transit_network_builder/data/\"\n",
    "mvta_url = \"http://wiki.mvta.com/files/Home/google_transit.zip\"\n",
    "metrotransit_url = \"ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/trans_transit_schedule_google_fd/csv_trans_transit_schedule_google_fd.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "roadway_network_file = \"C:/Users/wangs1/Documents/Met_Council/osm_roadway_network_builder/drive_link.shp\"\n",
    "roadway_gdf = gpd.read_file(roadway_network_file)\n",
    "node_file = \"C:/Users/wangs1/Documents/Met_Council/centroid_connector_builder/drive_node.shp\"\n",
    "node_gdf = gpd.read_file(node_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.save_load.load_graphml(\"C:/Users/wangs1/Documents/Met_Council/data/network-shape_MetCouncil_full/osm_networktype_drive/drive.graphml\")\n",
    "#G = nx.from_pandas_edgelist(roadway_gdf, 'A', 'B', 'DISTANCE',  create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#route type reference\n",
    "bus_routetype_df = pd.DataFrame(iter(DBF(\"C:/Users/wangs1/Documents/Met_Council/GIS/shp_trans_transit_routes/TransitRoutes.dbf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(cd, url, roadway, node, G):\n",
    "    \n",
    "    roadway_gdf = roadway.copy()\n",
    "    node_gdf = node.copy()\n",
    "    \n",
    "    # get feed for the busiest day\n",
    "    feed = get_representative_feed_from_gtfs(cd, url)\n",
    "\n",
    "    # standard trip reference\n",
    "    trip_df = get_representative_trip_for_route(feed)\n",
    "\n",
    "    # standard stop reference\n",
    "    stop_to_node_df = snap_stop_to_node(feed, node_gdf)\n",
    "    stop_df = pd.merge(feed.stops, stop_to_node_df[['N','OSMID', 'stop_id']],\n",
    "                  how = 'left',\n",
    "                  on = 'stop_id')\n",
    "\n",
    "    # chained stops on selected trips\n",
    "    chained_stop_to_node_df = representative_chained_stop_snap_node(feed, trip_df, stop_to_node_df)\n",
    "\n",
    "    # use osmnx to route the bus onto roadway network, return link_id the bus traverses\n",
    "    bus_shape_df, broken_shape_trip = match_bus_trip_shape_to_osm_link(roadway_gdf, \n",
    "                                                                   node_gdf, \n",
    "                                                                   G, feed, \n",
    "                                                                   trip_df, \n",
    "                                                                   chained_stop_to_node_df)\n",
    "    #initialize\n",
    "    rail_node_df = False\n",
    "    \n",
    "    if sum(feed.routes.route_type != 3) > 0:\n",
    "        # create rail links between stops\n",
    "        rail_shape_df, rail_node_df = non_bus_shape(feed, \n",
    "                                            trip_df, \n",
    "                                            chained_stop_to_node_df)\n",
    "\n",
    "        # combine bus and rail shape reference, and add rail links and nodes to roadway system\n",
    "        shape_df, roadway_and_rail_link_gdf, roadway_and_rail_node_gdf, rail_node_df = combine_bus_and_rail_shape(bus_shape_df, \n",
    "                                                                                            rail_shape_df, \n",
    "                                                                                            rail_node_df, \n",
    "                                                                                            roadway_gdf, \n",
    "                                                                                            node_gdf)\n",
    "    else:\n",
    "        shape_df = bus_shape_df.copy()\n",
    "        roadway_and_rail_link_gdf = roadway_gdf.copy()\n",
    "        roadway_and_rail_node_gdf = node_gdf.copy()\n",
    "\n",
    "    # create frequency reference\n",
    "    freq_df = create_freq_table(trip_df)\n",
    "\n",
    "    # write transit standard\n",
    "    write_out_transit_standard(trip_df, stop_df, shape_df, broken_shape_trip, freq_df, feed, rail_node_df)\n",
    "\n",
    "    # write shape files\n",
    "    #write_out_transit_embedded_roadway_network(roadway_and_rail_link_gdf, roadway_and_rail_node_gdf)\n",
    "\n",
    "    return feed, trip_df, stop_df, chained_stop_to_node_df, broken_shape_trip, shape_df, \\\n",
    "            roadway_and_rail_link_gdf, roadway_and_rail_node_gdf, rail_node_df, freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_feed_from_gtfs(work_dir, in_url):\n",
    "    \n",
    "    print('getting representative feed...')\n",
    "    \n",
    "    # read and save zip from url\n",
    "    #resp = urlopen(in_url)\n",
    "    #zipfile = ZipFile(BytesIO(resp.read()))\n",
    "    if 'mvta' in in_url:\n",
    "        #zipfile.extractall(cd + \"google_transit_mvta\")\n",
    "        file_loc = cd + \"google_transit_mvta\"\n",
    "    else:\n",
    "        #zipfile.extractall(cd + \"csv_trans_transit_schedule_google_fd\")\n",
    "        file_loc = cd + \"csv_trans_transit_schedule_google_fd\"\n",
    "    \n",
    "    # get feed for the busiest day\n",
    "    feed = pt.get_representative_feed(file_loc)\n",
    "    \n",
    "    return feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pick representatives for each route by direction, with most number of trip \n",
    "def get_representative_trip_for_route(feed):\n",
    "    \n",
    "    print('getting representative trip...')\n",
    "    \n",
    "    # get the first stop of each trip, process time\n",
    "    stop_times_df = feed.stop_times.copy()\n",
    "    stop_times_df['arrival_h'] = pd.to_datetime(stop_times_df['arrival_time'], unit = 's').dt.hour\n",
    "    stop_times_df['arrival_m'] = pd.to_datetime(stop_times_df['arrival_time'], unit = 's').dt.minute\n",
    "    stop_times_df['departure_h'] = pd.to_datetime(stop_times_df['departure_time'], unit = 's').dt.hour\n",
    "    stop_times_df['departure_m'] = pd.to_datetime(stop_times_df['departure_time'], unit = 's').dt.minute\n",
    "    first_stop_df = stop_times_df[stop_times_df['stop_sequence'] == 1]\n",
    "    \n",
    "    ## identify peak, offpeak trips, based on the arrival time of first stop\n",
    "    trip_df = feed.trips.copy()\n",
    "    trip_df = pd.merge(trip_df, first_stop_df,\n",
    "                      how = 'left',\n",
    "                      on = 'trip_id')\n",
    "    ## peak: 6-9am, offpeak: 9am-3pm\n",
    "    trip_df['tod'] = np.where((trip_df['arrival_h'] >= 6) & (trip_df['arrival_h'] < 9),\n",
    "                             'peak',\n",
    "                             np.where((trip_df['arrival_h'] >= 9) & (trip_df['arrival_h'] < 15),\n",
    "                             'offpeak',\n",
    "                             'other'))\n",
    "    \n",
    "    # get the most frequent trip for each route, by direction, by time of day\n",
    "    ## trips share the same shape_id is considered being the same\n",
    "    ## first get the trip count for each shape_id\n",
    "    trip_freq_df = trip_df.groupby(['route_id', 'tod', 'direction_id', 'shape_id'])['trip_id'].count().to_frame().drop(index = 'other', level = 1)\n",
    "\n",
    "    ## then choose the most frequent shape_id for each route, frequency use the total number of trips\n",
    "    def agg(x):\n",
    "        m = x.shape_id.iloc[np.argmax(x.trip_id.values)]\n",
    "        return pd.Series({'trip_sum' : x.trip_id.sum(), 'shape_id' : m})\n",
    "   \n",
    "    trip_freq_df = trip_freq_df.reset_index().groupby(['route_id', 'tod', 'direction_id']).apply(agg)\n",
    "    \n",
    "    # retain the complete trip info of represent trip only\n",
    "    trip_rep_df = pd.merge(trip_df, trip_freq_df.reset_index(),\n",
    "                      how = 'inner',\n",
    "                      on = ['route_id', 'tod', 'direction_id', 'shape_id']).drop_duplicates(['route_id', 'direction_id', 'tod'])\n",
    "    \n",
    "    return trip_rep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def snap_stop_to_node(feed, node_gdf):\n",
    "    \n",
    "    print('snapping gtfs stops to roadway nodes...')\n",
    "    \n",
    "    node_non_c_gdf = node_gdf[node_gdf['N'] > 3061].copy().reset_index(drop = True)\n",
    "    inventory_node_ref = node_non_c_gdf[['X', 'Y']].values\n",
    "    tree = cKDTree(inventory_node_ref)\n",
    "    \n",
    "    stop_df = feed.stops.copy()\n",
    "    stop_df['geometry'] = [Point(xy) for xy in zip(stop_df['stop_lon'], stop_df['stop_lat'])]\n",
    "    stop_df = gpd.GeoDataFrame(stop_df)\n",
    "    stop_df.crs = {'init' : 'epsg:4326'}\n",
    "    stop_df = stop_df.to_crs(node_non_c_gdf.crs)\n",
    "    stop_df['X'] = stop_df['geometry'].apply(lambda p: p.x)\n",
    "    stop_df['Y'] = stop_df['geometry'].apply(lambda p: p.y)\n",
    "   \n",
    "    for i in range(len(stop_df)):\n",
    "        point = stop_df.iloc[i][['X', 'Y']].values\n",
    "        dd, ii = tree.query(point, k = 1)\n",
    "        add_snap_gdf = gpd.GeoDataFrame(node_non_c_gdf.iloc[ii]).transpose().reset_index(drop = True)\n",
    "        add_snap_gdf['stop_id'] = stop_df.iloc[i]['stop_id']\n",
    "        if i == 0:\n",
    "            stop_to_node_gdf = add_snap_gdf.copy()\n",
    "        else:\n",
    "            stop_to_node_gdf = stop_to_node_gdf.append(add_snap_gdf, ignore_index=True, sort=False)\n",
    "    \n",
    "    return stop_to_node_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_chained_stop_snap_node(feed, trip_df, stop_to_node_df):\n",
    "    \n",
    "    print('getting representative chained stops...')\n",
    "    \n",
    "    stop_time_df = feed.stop_times.copy()\n",
    "    chained_stop_df = stop_time_df[stop_time_df['trip_id'].isin(trip_df.trip_id.tolist())]\n",
    "    chained_stop_to_node_df = pd.merge(chained_stop_df, stop_to_node_df,\n",
    "                                            how = 'left',\n",
    "                                            on = 'stop_id')\n",
    "    \n",
    "    return chained_stop_to_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def match_bus_trip_shape_to_osm_link(roadway_gdf, node_gdf, G, feed, trip, chained_stop_to_node):\n",
    "    \n",
    "    print('routing bus on roadway network...')\n",
    "    \n",
    "    osm_node_dict = dict(zip(node_gdf.OSMID, node_gdf.N))\n",
    "    \n",
    "    trip_df = trip.copy()\n",
    "    trip_df = pd.merge(trip_df, feed.routes, how = 'left', on = 'route_id')\n",
    "    bus_trip_df = trip_df[trip_df['route_type'] == 3]\n",
    "    \n",
    "    non_duplicate_busshape_trip_list = bus_trip_df.groupby('shape_id')['trip_id'].first().tolist()\n",
    "    \n",
    "    chained_stop_to_node_df = chained_stop_to_node.copy()\n",
    "    chained_stop_to_node_df = chained_stop_to_node_df[chained_stop_to_node_df.trip_id.isin(non_duplicate_busshape_trip_list)]\n",
    "    \n",
    "    broken_shape_trip_list = []\n",
    "    \n",
    "    for trip_id in chained_stop_to_node_df.trip_id.unique():\n",
    "        #print(trip_id)\n",
    "        trip_stop_df = chained_stop_to_node_df[chained_stop_to_node_df['trip_id'] == trip_id]\n",
    "        for s in range(len(trip_stop_df)-1):\n",
    "            try:\n",
    "                closest_node_to_stop1 = trip_stop_df.OSMID.iloc[s]\n",
    "                closest_node_to_stop2 = trip_stop_df.OSMID.iloc[s+1]\n",
    "                node_osmid_list = nx.shortest_path(G, closest_node_to_stop1, closest_node_to_stop2)\n",
    "                node_N_list = [osm_node_dict[x] for x in node_osmid_list if x in list(osm_node_dict.keys())]\n",
    "                osm_link_gdf = pd.merge(pd.DataFrame({'A' : node_N_list[:len(node_N_list)-1], \n",
    "                                                      'B' : node_N_list[1:len(node_N_list)]}),\n",
    "                                         roadway_gdf[['A', 'B', 'LINK_ID']],\n",
    "                                         how = 'left',\n",
    "                                         on = ['A', 'B'])\n",
    "                osm_link_gdf['trip_id'] = trip_id\n",
    "                if (trip_id == chained_stop_to_node_df.trip_id.unique()[0]) & (s==0):\n",
    "                    trip_shape_df = osm_link_gdf.copy()\n",
    "                else:\n",
    "                    trip_shape_df = trip_shape_df.append(osm_link_gdf, ignore_index = True, sort = False)\n",
    "            except:\n",
    "                broken_shape_trip_list = broken_shape_trip_list + [trip_id]\n",
    "                print('  warning: cannot route bus: ' + trip_id)\n",
    "                continue\n",
    "                \n",
    "    trip_shape_df = pd.merge(trip_shape_df, trip_df[['trip_id', 'shape_id']], how = 'left', on = 'trip_id') \n",
    "    \n",
    "    return trip_shape_df, broken_shape_trip_list\n",
    "#bus_shape_df = pd.merge(bus_shape_df, trip_df[['trip_id', 'shape_id']], how = 'left', on = 'trip_id')\n",
    "#n_list = chained_stop_to_node_df[chained_stop_to_node_df.trip_id == '14447646-MAR19-MVS-BUS-Weekday-01'].N.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rail links\n",
    "def non_bus_shape(feed, trip, chained_stop_to_node):\n",
    "    \n",
    "    print('generating rail links...')\n",
    "    \n",
    "    trip_df = trip.copy()\n",
    "    trip_df = pd.merge(trip_df, feed.routes[['route_id', 'route_type']], how = 'left', on = 'route_id')\n",
    "    non_bus_trip_df = trip_df[trip_df.route_type != 3]\n",
    "    \n",
    "    non_bus_chained_stop_df = chained_stop_to_node[chained_stop_to_node['trip_id'].isin(non_bus_trip_df.trip_id.tolist())]\n",
    "    \n",
    "    non_bus_shape_df = feed.shapes[feed.shapes['shape_id'].isin(non_bus_trip_df.shape_id.tolist())]\n",
    "    \n",
    "    shape_trip_dict = dict(zip(non_bus_trip_df.shape_id, non_bus_trip_df.trip_id))\n",
    "    \n",
    "    for i in non_bus_shape_df.shape_id.unique():\n",
    "        trip_id = shape_trip_dict[i]\n",
    "        \n",
    "        stop_df = non_bus_chained_stop_df[non_bus_chained_stop_df.trip_id == trip_id].copy()\n",
    "        stop_df = pd.merge(stop_df, feed.stops, how = 'left', on = 'stop_id')\n",
    "        shape_df = non_bus_shape_df[non_bus_shape_df.shape_id == i].copy()\n",
    "        shape_df['is_stop'] = np.int(0)\n",
    "        shape_df['stop_id'] = np.nan\n",
    "        shape_inventory = shape_df[['shape_pt_lon', 'shape_pt_lat']].values\n",
    "        tree = cKDTree(shape_inventory)\n",
    "        for s in range(len(stop_df)):\n",
    "            point = stop_df.iloc[s][['stop_lon', 'stop_lat']].values\n",
    "            dd, ii = tree.query(point, k = 1)\n",
    "            shape_df.is_stop.iloc[ii] = 1\n",
    "            shape_df.stop_id.iloc[ii] = stop_df.iloc[s]['stop_id']\n",
    "        if i == non_bus_shape_df.shape_id.unique()[0]:\n",
    "            shape_flag_df = shape_df.copy()\n",
    "        else:\n",
    "            shape_flag_df = shape_flag_df.append(shape_df, ignore_index = True, sort = False)\n",
    "      \n",
    "    linestring_df = pd.DataFrame(columns = ['shape_id', 'A', 'B', 'geometry', 'A_stop_id', 'B_stop_id'])\n",
    "\n",
    "    for i in shape_flag_df.shape_id.unique():\n",
    "        shape_route_df = shape_flag_df[shape_flag_df.shape_id == i]\n",
    "        break_list = shape_route_df.index[shape_route_df.is_stop == 1].tolist()\n",
    "        stop_id_list = shape_route_df[shape_route_df.is_stop == 1]['stop_id'].tolist()\n",
    "        for j in range(len(break_list)-1):\n",
    "            lon_list = shape_flag_df.shape_pt_lon.iloc[break_list[j]:break_list[j+1]+1].tolist()\n",
    "            lat_list = shape_flag_df.shape_pt_lat.iloc[break_list[j]:break_list[j+1]+1].tolist()\n",
    "            linestring = LineString([Point(xy) for xy in zip(lon_list,lat_list)])\n",
    "            linestring_df = linestring_df.append({'shape_id':i, \n",
    "                                                  'A':break_list[j], \n",
    "                                                  'B':break_list[j+1],\n",
    "                                                  'A_stop_id':stop_id_list[j], \n",
    "                                                  'B_stop_id':stop_id_list[j+1],\n",
    "                                                  'geometry' : linestring}, ignore_index = True, sort = False)\n",
    "    \n",
    "    #linestring_df = pd.merge(linestring_df, trip_df[['trip_id', 'shape_id']], how = 'left', on = 'shape_id')\n",
    "    \n",
    "    #rail_node_list = list(set(linestring_df['A'].tolist() + linestring_df['B'].tolist()))\n",
    "    #rail_node_df = non_bus_shape_df.reset_index(drop = True).loc[rail_node_list].rename_axis('node_id').reset_index().sort_values(by = 'node_id')\n",
    "    rail_node_df = shape_flag_df[shape_flag_df.is_stop == 1].rename_axis('node_id').reset_index()\n",
    "    \n",
    "    return linestring_df, rail_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_bus_and_rail_shape(bus_shape, rail_shape, rail_node, roadway_gdf, node_gdf):\n",
    "    \n",
    "    print('indexing rail links and nodes...')\n",
    "    \n",
    "    roadway_node_end_id = node_gdf.N.max()\n",
    "    roadway_link_end_id = roadway_gdf.LINK_ID.max()\n",
    "    \n",
    "    # add unique rail nodes to roadway node dataframe\n",
    "    rail_node_gdf = rail_node.copy()\n",
    "    \n",
    "    unique_rail_node_df = rail_node_gdf.drop_duplicates(['shape_pt_lat', 'shape_pt_lon']).copy()\n",
    "    unique_rail_node_df['N'] = range(roadway_node_end_id + 1, roadway_node_end_id + 1 + len(unique_rail_node_df))\n",
    "    \n",
    "    rail_node_gdf = pd.merge(rail_node_gdf, \n",
    "                            unique_rail_node_df[['shape_pt_lat', 'shape_pt_lon', 'N']], \n",
    "                            how = 'left', \n",
    "                            on = ['shape_pt_lat', 'shape_pt_lon'])\n",
    "    \n",
    "    rail_shape_df = rail_shape.copy()\n",
    "    rail_shape_df['A'] = rail_shape_df['A'].astype(int)\n",
    "    rail_shape_df['B'] = rail_shape_df['B'].astype(int)\n",
    "\n",
    "    rail_shape_df = pd.merge(rail_shape_df, rail_node_gdf[['node_id', 'N']], how = 'left', left_on = 'A', right_on='node_id')\n",
    "    rail_shape_df = pd.merge(rail_shape_df, rail_node_gdf[['node_id', 'N']], how = 'left', left_on = 'B', right_on='node_id')\n",
    "    \n",
    "    unique_rail_node_df['geometry'] = [Point(xy) for xy in zip(unique_rail_node_df.shape_pt_lon, \n",
    "                                                               unique_rail_node_df.shape_pt_lat)]\n",
    "    unique_rail_node_df = gpd.GeoDataFrame(unique_rail_node_df)\n",
    "    unique_rail_node_df.crs = {'init' : 'epsg:4326'}\n",
    "    unique_rail_node_df = unique_rail_node_df.to_crs(node_gdf.crs)\n",
    "    unique_rail_node_df['X'] = unique_rail_node_df['geometry'].apply(lambda p: p.x)\n",
    "    unique_rail_node_df['Y'] = unique_rail_node_df['geometry'].apply(lambda p: p.y)\n",
    "    unique_rail_node_df['OSMID'] = np.int(0)\n",
    "    \n",
    "    roadway_and_rail_node_gdf = node_gdf.append(unique_rail_node_df[node_gdf.columns.values], \n",
    "                                                ignore_index = True, \n",
    "                                                sort = False)\n",
    "    \n",
    "    # add unique rail links to roadway link dataframe\n",
    "    unique_rail_shape_gdf = rail_shape_df.drop_duplicates(['N_x', 'N_y']).copy()\n",
    "    unique_rail_shape_gdf.drop(['A', 'B'], axis = 1, inplace = True)\n",
    "    unique_rail_shape_gdf.rename(columns = {'N_x' : 'A', 'N_y' : 'B'}, inplace = True)\n",
    "    \n",
    "    unique_rail_shape_gdf['LINK_ID'] = range(roadway_link_end_id + 1, roadway_link_end_id + 1 + len(unique_rail_shape_gdf))\n",
    "    unique_rail_shape_gdf = gpd.GeoDataFrame(unique_rail_shape_gdf)\n",
    "    unique_rail_shape_gdf.crs = {'init' : 'epsg:4326'}\n",
    "    unique_rail_shape_gdf = unique_rail_shape_gdf.to_crs(roadway_gdf.crs)\n",
    "    \n",
    "    roadway_and_rail_link_gdf = roadway_gdf.append(unique_rail_shape_gdf[['A', 'B', 'LINK_ID', 'geometry']], \n",
    "                                                   ignore_index = True, \n",
    "                                                   sort = False)\n",
    "    \n",
    "    print('combining bus and rail shapes...')\n",
    "    \n",
    "    bus_shape_df = bus_shape.copy()\n",
    "    shape_df = bus_shape_df[['shape_id', 'A', 'B', 'LINK_ID']].append(unique_rail_shape_gdf[['shape_id', 'A', 'B', 'LINK_ID']])\n",
    "    \n",
    "    return shape_df, roadway_and_rail_link_gdf, roadway_and_rail_node_gdf, rail_node_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_freq_table(trip_df):\n",
    "    \n",
    "    print('creating frequency reference...')\n",
    "    \n",
    "    freq_df = trip_df[['trip_id', 'tod', 'direction_id', 'trip_sum']].copy()\n",
    "    freq_df['headway_secs'] = np.where(freq_df.tod == 'peak', (3*60*60/freq_df.trip_sum).astype(int),\n",
    "                      (6*60*60/freq_df.trip_sum).astype(int))\n",
    "    \n",
    "    return freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_out_transit_standard(trip, stop, shape, broken_trip, freq, feed, rail_node = False):\n",
    "    \n",
    "    shape_df = shape.copy()\n",
    "    trip_df = trip.copy()\n",
    "    \n",
    "    broken_shape_list = shape_df[shape_df.LINK_ID.isnull()].shape_id.tolist()\n",
    "    broken_shape_list = broken_shape_list + trip_df[trip_df.trip_id.isin(broken_trip)].shape_id.tolist()\n",
    "    \n",
    "    shape_df = shape_df[-shape_df.shape_id.isin(broken_shape_list)]\n",
    "    shape_df['LINK_ID'] = shape_df['LINK_ID'].astype(int)\n",
    "    shape_df['LINK_ID'] = shape_df.apply(lambda x: 'driveLink' + str(x.LINK_ID), axis = 1) \n",
    "    shape_df['A'] = shape_df.apply(lambda x: 'driveNode' + str(x.A), axis = 1)\n",
    "    shape_df['B'] = shape_df.apply(lambda x: 'driveNode' + str(x.B), axis = 1)\n",
    "    \n",
    "    trip_df = trip_df[-((trip_df.shape_id.isin(broken_shape_list)) | (trip_df.trip_id.isin(broken_trip)))]\n",
    "    \n",
    "    final_trip_list = trip_df.trip_id.unique().tolist()\n",
    "    \n",
    "    freq_df = freq.copy()\n",
    "    freq_df = freq_df[freq_df.trip_id.isin(final_trip_list)]\n",
    "    \n",
    "    stop_df = stop.copy()\n",
    "    \n",
    "    if type(rail_node) != bool:\n",
    "        rail_node_df = rail_node.copy()\n",
    "        rail_node_dict = dict(zip(rail_node_df.stop_id, rail_node_df.N))\n",
    "        stop_df['N'] = stop_df.apply(lambda x: rail_node_dict[x.stop_id] if x.stop_id in rail_node_df.stop_id.tolist()else x.N,\n",
    "                                axis = 1)\n",
    "    \n",
    "    stop_df['N'] = stop_df.apply(lambda x: 'driveNode' + str(x.N), axis = 1)\n",
    "    \n",
    "    route_df = feed.routes.copy()\n",
    "    route_df = route_df[route_df.route_id.isin(trip_df.route_id.tolist())]\n",
    "    \n",
    "    route_df.to_csv(cd + 'output/routes.txt', index = False, sep = ',')\n",
    "    shape_df.to_csv(cd + 'output/shapes.txt', index = False, sep = ',')\n",
    "    trip_df[feed.trips.columns.values].to_csv(cd + 'output/trips.txt', index = False, sep = ',')\n",
    "    freq_df[['trip_id', 'headway_secs']].to_csv(cd + 'output/frequencies.txt', index = False, sep = ',')\n",
    "    stop_df.to_csv(cd + 'output/stops.txt', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_transit_embedded_roadway_network(link, node):\n",
    "    link.to_file(cd + 'output/drive_link_with_rail.shp')\n",
    "    node.to_file(cd + 'output/drive_node_with_rail.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_metro_mvta_txt():\n",
    "    name_list = ['metro', 'mvta']\n",
    "    file_list = ['routes', 'trips', 'stops', 'frequencies', 'shapes']\n",
    "    mvta_agency = {1:3, 2:0, 3:15}\n",
    "    for f in file_list:\n",
    "        all_df = pd.DataFrame()\n",
    "        for n in name_list:\n",
    "            sub_df = pd.read_csv(cd + 'output/' + f + '_' + n + '.txt')\n",
    "            if (f == 'routes')&(n == 'mvta'):\n",
    "                sub_df['agency_id'] = sub_df['agency_id'].map(mvta_agency)\n",
    "            if f == 'shapes':\n",
    "                sub_df = sub_df[['shape_id', 'A', 'B', 'LINK_ID']]\n",
    "            all_df = all_df.append(sub_df, ignore_index = True, sort = False)\n",
    "            all_df.to_csv(cd + 'output/' + f + '.txt', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting representative feed...\n",
      "getting representative trip...\n",
      "snapping gtfs stops to roadway nodes...\n",
      "getting representative chained stops...\n",
      "routing bus on roadway network...\n",
      "  warning: cannot route bus: 14451973-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14451974-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14451974-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14451987-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14451987-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452410-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452411-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452496-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452505-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452518-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452531-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14452866-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454164-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454165-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454165-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454612-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454612-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454893-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454893-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454896-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454896-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14454899-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14455255-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14455509-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14455522-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14455631-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14485991-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14495156-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14495156-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14498628-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14498646-MAR19-MVS-BUS-Weekday-01\n",
      "  warning: cannot route bus: 14499726-MAR19-MVS-BUS-Weekday-01\n",
      "generating rail links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\metC\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing rail links and nodes...\n",
      "combining bus and rail shapes...\n",
      "creating frequency reference...\n"
     ]
    }
   ],
   "source": [
    "metro_feed, metro_trip_df, metro_stop_df, metro_chained_stop_to_node_df, metro_broken_shape_trip, metro_shape_df, \\\n",
    "        metro_roadway_and_rail_link_gdf, metro_roadway_and_rail_node_gdf, \\\n",
    "        metro_rail_node_df, metro_freq_df = main(cd, \n",
    "                                               metrotransit_url, \n",
    "                                               roadway_gdf,#roadway_and_rail_link_gdf, \n",
    "                                               node_gdf,#roadway_and_rail_node_gdf,\n",
    "                                              G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting representative feed...\n",
      "getting representative trip...\n",
      "snapping gtfs stops to roadway nodes...\n",
      "getting representative chained stops...\n",
      "routing bus on roadway network...\n",
      "  warning: cannot route bus: 031-CT-480.1N-0601-20181117-Weekday-06\n",
      "  warning: cannot route bus: 061-RL-472.1N-0623-20181117-Weekday-06\n",
      "  warning: cannot route bus: 319-CT-472.2S-1404-20181117-Weekday-06\n",
      "  warning: cannot route bus: 022-S1-438.1E-0850-20181117-Weekday-06\n",
      "  warning: cannot route bus: 022-S1-438.1W-1117-20181117-Weekday-06\n",
      "  warning: cannot route bus: 951--411.0N-0819-20181117-Weekday-06\n",
      "  warning: cannot route bus: 415-CT-493.0S-1431-20181117-Weekday-06\n",
      "  warning: cannot route bus: 250-S2-497.2E-0601-20181117-Weekday-06\n",
      "  warning: cannot route bus: 251-S2-499.1W-0611-20181117-Weekday-06\n",
      "  warning: cannot route bus: 250-S2-499.0W-0906-20181117-Weekday-06\n",
      "  warning: cannot route bus: 120-RL-495.0W-0759-20181117-Weekday-06\n",
      "  warning: cannot route bus: 339-CT-490.8S-1245-20181117-Weekday-06\n",
      "creating frequency reference...\n"
     ]
    }
   ],
   "source": [
    "mvta_feed, mvta_trip_df, mvta_stop_df, mvta_chained_stop_to_node_df, mvta_broken_shape_trip, mvta_shape_df, \\\n",
    "        mvta_roadway_and_rail_link_gdf, mvta_roadway_and_rail_node_gdf, \\\n",
    "        mvta_rail_node_df, mvta_freq_df = main(cd, \n",
    "                                               mvta_url, \n",
    "                                               roadway_gdf,#roadway_and_rail_link_gdf, \n",
    "                                               node_gdf,#roadway_and_rail_node_gdf,\n",
    "                                              G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_metro_mvta_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_for_cube(feed, trip, shape, chained_stop_to_node, freq, broken_trip, bus_routetype, url):\n",
    "    \n",
    "    mode_dict = {0:8, 2:9}\n",
    "    bus_mode_dict = {'Urb Loc':5, 'Sub Loc':6, 'Express':7}\n",
    "    metro_operator_dict = {'0':3, '1':3, '2':3, '3':4, '4':2, '5':5, '6':8, '7':1, '8':1, '9':10, '10':3, \n",
    "                           '11':9, '12':3, '13':4, '14':4, '15':3}\n",
    "    mvta_operator_dict = {'1':4, '2':3, '3':3}\n",
    "    \n",
    "    routetype_df = bus_routetype.copy()\n",
    "    \n",
    "    shape_df = shape.copy()\n",
    "    trip_df = trip.copy()\n",
    "    \n",
    "    broken_shape_list = shape_df[shape_df.LINK_ID.isnull()].shape_id.tolist()\n",
    "    broken_shape_list = broken_shape_list + trip_df[trip_df.trip_id.isin(broken_trip)].shape_id.tolist()\n",
    "    \n",
    "    \n",
    "    trip_df = trip_df[-((trip_df.shape_id.isin(broken_shape_list)) | (trip_df.trip_id.isin(broken_trip)))]\n",
    "    \n",
    "    trip_df = pd.merge(trip_df, feed.routes, how = 'left', on = 'route_id')\n",
    "    trip_df = pd.merge(trip_df, freq, how = 'left', on = 'trip_id')\n",
    "    trip_df = pd.merge(trip_df, routetype_df[['route', 'routetype']], \n",
    "                       how = 'left', left_on = 'route_short_name', right_on = 'route')\n",
    "    \n",
    "    trip_df['NAME'] = trip_df.apply(lambda x: x.agency_id + '_' + x.route_id + '_' + x.route_short_name + \\\n",
    "                                    '_' + x.tod_x + '_' + 'dir' + str(x.direction_id_x), \n",
    "                                    axis = 1)\n",
    "    trip_df['LONGNAME'] = trip_df['route_long_name']\n",
    "    trip_df['HEADWAY'] = (trip_df['headway_secs']/60).astype(int)\n",
    "    trip_df['MODE'] = np.where(trip_df.route_type == 3, \n",
    "                               trip_df['routetype'].map(bus_mode_dict),\n",
    "                               trip_df['route_type'].map(mode_dict))\n",
    "    trip_df['MODE'].fillna(5, inplace = True)\n",
    "    trip_df['MODE'] = trip_df['MODE'].astype(int)\n",
    "    \n",
    "    trip_df['ONEWAY'] = 'T'\n",
    "    \n",
    "    if 'mvta' in url:\n",
    "        trip_df['OPERATOR'] = trip_df['agency_id'].map(mvta_operator_dict)\n",
    "    else:\n",
    "        trip_df['OPERATOR'] = trip_df['agency_id'].map(metro_operator_dict)\n",
    "    \n",
    "    return trip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_cube = prepare_df_for_cube(metro_feed, \n",
    "                                metro_trip_df, \n",
    "                                metro_shape_df, \n",
    "                                metro_chained_stop_to_node_df, \n",
    "                                metro_freq_df, \n",
    "                                metro_broken_shape_trip, \n",
    "                                bus_routetype_df,\n",
    "                                metrotransit_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 40)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metro_cube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvta_cube = prepare_df_for_cube(mvta_feed, \n",
    "                                mvta_trip_df, \n",
    "                                mvta_shape_df, \n",
    "                                mvta_chained_stop_to_node_df, \n",
    "                                mvta_freq_df, \n",
    "                                mvta_broken_shape_trip, \n",
    "                                bus_routetype_df,\n",
    "                                mvta_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 47)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvta_cube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>direction_id_x</th>\n",
       "      <th>block_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>wheelchair_accessible</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_sum_y</th>\n",
       "      <th>headway_secs</th>\n",
       "      <th>route</th>\n",
       "      <th>routetype</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LONGNAME</th>\n",
       "      <th>HEADWAY</th>\n",
       "      <th>MODE</th>\n",
       "      <th>ONEWAY</th>\n",
       "      <th>OPERATOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [route_id, service_id, trip_id, trip_headsign, direction_id_x, block_id, shape_id, wheelchair_accessible, arrival_time, departure_time, stop_id, stop_sequence, pickup_type, drop_off_type, arrival_h, arrival_m, departure_h, departure_m, tod_x, trip_sum_x, agency_id, route_short_name, route_long_name, route_desc, route_type, route_url, route_color, route_text_color, tod_y, direction_id_y, trip_sum_y, headway_secs, route, routetype, NAME, LONGNAME, HEADWAY, MODE, ONEWAY, OPERATOR]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metro_cube[metro_cube.MODE.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>trip_headsign</th>\n",
       "      <th>trip_destination</th>\n",
       "      <th>trip_short_name</th>\n",
       "      <th>trip_route_name</th>\n",
       "      <th>direction_id_x</th>\n",
       "      <th>pub_dir_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_sum_y</th>\n",
       "      <th>headway_secs</th>\n",
       "      <th>route</th>\n",
       "      <th>routetype</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LONGNAME</th>\n",
       "      <th>HEADWAY</th>\n",
       "      <th>MODE</th>\n",
       "      <th>ONEWAY</th>\n",
       "      <th>OPERATOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [route_id, service_id, trip_id, trip_headsign, trip_destination, trip_short_name, trip_route_name, direction_id_x, pub_dir_id, block_id, rm_block_id, shape_id, arrival_time, departure_time, stop_id, stop_distance, stop_sequence, pickup_type, drop_off_type, timepoint, stop_is_skipped, arrival_h, arrival_m, departure_h, departure_m, tod_x, trip_sum_x, agency_id, route_short_name, route_long_name, route_desc, route_type, route_url, route_color, route_text_color, tod_y, direction_id_y, trip_sum_y, headway_secs, route, routetype, NAME, LONGNAME, HEADWAY, MODE, ONEWAY, OPERATOR]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 47 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvta_cube[mvta_cube.routetype.isnull()]\n",
    "mvta_cube[mvta_cube.MODE.isnull()]\n",
    "#temp.groupby(['MODE', 'route_short_name']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def node_list(x, rail_node_df, chained_stop_to_node_df, stop_df, shape_df):\n",
    "    \n",
    "    if type(rail_node_df) != bool:\n",
    "        rail_node_dict = dict(zip(rail_node_df.stop_id, rail_node_df.N))\n",
    "        stop_df['N'] = stop_df.apply(lambda x: rail_node_dict[x.stop_id] if x.stop_id in rail_node_df.stop_id.tolist()else x.N,\n",
    "                                    axis = 1)\n",
    "        \n",
    "    stop_id_list = chained_stop_to_node_df[chained_stop_to_node_df.trip_id == x.trip_id]['stop_id'].tolist()\n",
    "    stop_node_list = stop_df[stop_df['stop_id'].isin(stop_id_list)]['N'].tolist()\n",
    "    \n",
    "    node_list = shape_df[shape_df['shape_id'] == x.shape_id]['A'].tolist() + \\\n",
    "                    [shape_df[shape_df['shape_id'] == x.shape_id]['B'].iloc[-1]]\n",
    "    \n",
    "    s = '\\nLINE NAME=\\\"%s\\\",' % (x.NAME,)\n",
    "    \n",
    "    #line attribtes\n",
    "    s += '\\n LONGNAME=\\\"%s\",' % (x.LONGNAME,)\n",
    "    if x.tod_y == 'peak':\n",
    "        s += '\\n HEADWAY=%s,' % (x.HEADWAY,)\n",
    "    else:\n",
    "        s += '\\n HEADWAY[2]=%s,' % (x.HEADWAY,)\n",
    "    s += '\\n MODE=%s,' % (x.MODE,)\n",
    "    s += '\\n ONEWAY=%s,' % (x.ONEWAY,)\n",
    "    s += '\\n OPERATOR=%s,' % (x.OPERATOR,)\n",
    "    s += '\\nNODES='\n",
    "    \n",
    "    #node list\n",
    "    for nodeIdx in range(len(node_list)):\n",
    "        if node_list[nodeIdx] in stop_node_list:\n",
    "            s += '\\n %s' % (node_list[nodeIdx])\n",
    "            if nodeIdx < (len(node_list)-1):\n",
    "                s += ','\n",
    "        else:\n",
    "            s += '\\n -%s' % (node_list[nodeIdx])\n",
    "            if nodeIdx < (len(node_list)-1):\n",
    "                s += ','\n",
    "            \n",
    "    lines.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [';;<<PT>><<LINE>>;;']\n",
    "\n",
    "metro_cube.apply(lambda x: node_list(x, \n",
    "                                    metro_rail_node_df, \n",
    "                                    metro_chained_stop_to_node_df, \n",
    "                                    metro_stop_df, \n",
    "                                    metro_shape_df), \n",
    "                axis=1)\n",
    "\n",
    "mvta_cube.apply(lambda x: node_list(x, \n",
    "                                    mvta_rail_node_df, \n",
    "                                    mvta_chained_stop_to_node_df, \n",
    "                                    mvta_stop_df, \n",
    "                                    mvta_shape_df), \n",
    "                axis=1)\n",
    "\n",
    "with open('C:/Users/wangs1/Documents/Met_Council/Network Standard/transit.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#node_list(temp.iloc[-1])\n",
    "#temp.trip_id\n",
    "#print(lines)\n",
    "lines = [';;<<PT>><<LINE>>;;']\n",
    "\n",
    "mvta_cube.apply(lambda x: node_list(x, \n",
    "                                    mvta_rail_node_df, \n",
    "                                    mvta_chained_stop_to_node_df, \n",
    "                                    mvta_stop_df, \n",
    "                                    mvta_shape_df), \n",
    "                axis=1)\n",
    "\n",
    "with open('C:/Users/wangs1/Documents/Met_Council/Network Standard/mvta_transit_new3.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, lines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roadway_with_rail_link_gdf = gpd.read_file(cd + 'output/drive_link_with_rail.shp')\n",
    "#roadway_with_rail_node_gdf = gpd.read_file(cd + 'output/drive_node_with_rail.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "roadway_with_rail_link_gdf = gpd.read_file(cd + 'output/drive_link_with_rail.shp')\n",
    "roadway_with_rail_link_gdf['ASGNGRP'] = np.where(roadway_with_rail_link_gdf['ASGNGRP'] == 0,\n",
    "                                                1, roadway_with_rail_link_gdf['ASGNGRP'])\n",
    "\n",
    "roadway_with_rail_link_gdf['RC_NUM'] = np.where(roadway_with_rail_link_gdf['RC_NUM'] == 0,\n",
    "                                                20, roadway_with_rail_link_gdf['RC_NUM'])\n",
    "\n",
    "roadway_with_rail_link_gdf.fillna(0, inplace = True)\n",
    "float_list = roadway_with_rail_link_gdf.columns[(roadway_with_rail_link_gdf.dtypes.values == np.dtype('float64'))]\n",
    "for x in float_list:\n",
    "    roadway_with_rail_link_gdf[x] = roadway_with_rail_link_gdf[x].astype(int)\n",
    "    \n",
    "roadway_with_rail_link_gdf.drop(['DISTANCE', 'T_MANTIME'], axis = 1).to_file(cd + 'output/drive_and_rail_link.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from osgeo import ogr\n",
    "\n",
    "def shp_float_fields(network_type = 'drive'):\n",
    "    #additional step to add float fields\n",
    "    source = ogr.Open(cd + 'output/drive_and_rail_link.shp', update=True)\n",
    "    layer = source.GetLayer()\n",
    "    layer_defn = layer.GetLayerDefn()\n",
    "    field_names = [layer_defn.GetFieldDefn(i).GetName() for i in range(layer_defn.GetFieldCount())]\n",
    "    print(len(field_names))\n",
    "\n",
    "    #Add a new field - DISTANCE\n",
    "    new_field = ogr.FieldDefn('DISTANCE', ogr.OFTReal)\n",
    "    new_field.SetWidth(10)\n",
    "    new_field.SetPrecision(5)\n",
    "    if ('DISTANCE' in field_names) == False:\n",
    "        layer.CreateField(new_field)\n",
    "\n",
    "    #for i in layer:\n",
    "    #    geom = i.GetGeometryRef()\n",
    "    #    length = (geom.Length())/1609.344\n",
    "    #    i.SetField( \"DISTANCE\", length)\n",
    "    #    layer.SetFeature(i)\n",
    "\n",
    "    #Add a new field - T_MANTIME\n",
    "    if network_type == 'drive':\n",
    "        new_field = ogr.FieldDefn('T_MANTIME', ogr.OFTReal)\n",
    "        new_field.SetWidth(10) \n",
    "        new_field.SetPrecision(5)\n",
    "        if ('T_MANTIME' in field_names) == False:\n",
    "            layer.CreateField(new_field)\n",
    "\n",
    "    for i in layer:\n",
    "        geom = i.GetGeometryRef()\n",
    "        length = (geom.Length())/1609.344\n",
    "        i.SetField( \"DISTANCE\", length)\n",
    "        if network_type == 'drive':\n",
    "            i.SetField( \"T_MANTIME\", 0)\n",
    "        layer.SetFeature(i)\n",
    "\n",
    "    # Close the Shapefile\n",
    "    source = None\n",
    "\n",
    "\n",
    "shp_float_fields()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create subset for transit st paul\n",
    "poly_gdf = gpd.read_file(\"W:/Users/wangs1/Documents/Met_Council/Network Standard/poly2.shp\")\n",
    "poly_gdf = poly_gdf.to_crs(roadway_gdf.crs)\n",
    "\n",
    "bus_routetype_gdf = gpd.read_file(\"W:/Users/wangs1/Documents/Met_Council/GIS/shp_trans_transit_routes/TransitRoutes.shp\")\n",
    "\n",
    "st_transit = bus_routetype_gdf[bus_routetype_gdf.intersects(poly_gdf.geometry[0])]\n",
    "\n",
    "def write_out_transit_standard_subset(trip, stop, shape, broken_trip, freq, feed, st_tran, rail_node = False):\n",
    "    \n",
    "    shape_df = shape.copy()\n",
    "    broken_shape_list = shape_df[shape_df.LINK_ID.isnull()].shape_id.tolist()\n",
    "    \n",
    "    #shape_df = shape_df[-shape_df.shape_id.isin(broken_shape_list)]\n",
    "    #shape_df = shape_df[shape_df.shape_id.isin(st_tran.)]\n",
    "    \n",
    "    \n",
    "    trip_df = trip.copy()\n",
    "    trip_df = trip_df[-((trip_df.shape_id.isin(broken_shape_list)) | (trip_df.trip_id.isin(broken_trip)))]\n",
    "    trip_df = pd.merge(trip_df, feed.routes[['route_id', 'route_short_name']], how = 'left', on = 'route_id') \n",
    "    trip_df = trip_df[trip_df.route_short_name.isin(st_tran.route.tolist())]\n",
    "    \n",
    "    final_trip_list = trip_df.trip_id.unique().tolist()\n",
    "    final_shape_list = trip_df.shape_id.unique().tolist()\n",
    "    \n",
    "    shape_df = shape_df[shape_df.shape_id.isin(final_shape_list)]\n",
    "    shape_df['LINK_ID'] = shape_df['LINK_ID'].astype(int)\n",
    "    shape_df['LINK_ID'] = shape_df.apply(lambda x: 'driveLink' + str(x.LINK_ID), axis = 1)\n",
    "    shape_df['A'] = shape_df.apply(lambda x: 'driveNode' + str(x.A), axis = 1)\n",
    "    shape_df['B'] = shape_df.apply(lambda x: 'driveNode' + str(x.B), axis = 1)\n",
    "    \n",
    "    freq_df = freq.copy()\n",
    "    freq_df = freq_df[freq_df.trip_id.isin(final_trip_list)]\n",
    "    \n",
    "    stop_df = stop.copy()\n",
    "    \n",
    "    if type(rail_node) != bool:\n",
    "        rail_node_df = rail_node.copy()\n",
    "        rail_node_dict = dict(zip(rail_node_df.stop_id, rail_node_df.N))\n",
    "        stop_df['N'] = stop_df.apply(lambda x: rail_node_dict[x.stop_id] if x.stop_id in rail_node_df.stop_id.tolist()else x.N,\n",
    "                                axis = 1)\n",
    "    \n",
    "    stop_df['N'] = stop_df.apply(lambda x: 'driveNode' + str(x.N), axis = 1)\n",
    "    \n",
    "    route_df = feed.routes.copy()\n",
    "    route_df = route_df[route_df.route_short_name.isin(st_tran.route.tolist())]\n",
    "    \n",
    "    route_df.to_csv(cd + 'output/st_routes.txt', index = False, sep = ',')\n",
    "    shape_df.to_csv(cd + 'output/st_shapes.txt', index = False, sep = ',')\n",
    "    trip_df[feed.trips.columns.values].to_csv(cd + 'output/st_trips.txt', index = False, sep = ',')\n",
    "    freq_df[['trip_id', 'headway_secs']].to_csv(cd + 'output/st_frequencies.txt', index = False, sep = ',')\n",
    "    stop_df.to_csv(cd + 'output/st_stops.txt', index = False, sep = ',')\n",
    "\n",
    "write_out_transit_standard_subset(metro_trip_df, metro_stop_df, metro_shape_df, \n",
    "                                  metro_broken_shape_trip, metro_freq_df, metro_feed, st_transit, metro_rail_node_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (metC)",
   "language": "python",
   "name": "metc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
